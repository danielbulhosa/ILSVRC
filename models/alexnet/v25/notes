Same as v24 but replacing all convolutional batchnorms
with LRN layers and adding a ShiftScaleRotate transformation
with limits shift=0.1, scale=0.2, rotate=25. Also going to start
dividing learning rate by 2 instead of 10.
